---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently doing my PhD under the supervision of [Dr. Kosta Derpanis](https://cs.ryerson.ca/~kosta/) at [York University](https://www.yorku.ca/). I am a postgraduate affiliate at the [Vector Institute](https://vectorinstitute.ai/) and the Lead Scientist in Residence at [NextAI](https://www.nextcanada.com/next-ai/). My research interests are in the domain of explainable computer vision with a focus on image and video understanding tasks.

I completed a Bachelors of Applied Science (B.A.Sc) in [Applied Mathematics and Engineering](https://www.queensu.ca/mathstat/mthe) with a specialization in Mechanical Engineering at [Queen's University](https://www.queensu.ca/) in Kingston, Ontario, Canada. After graduating from my Bachelors degree, I worked at [Morrison Hershfield](https://www.morrisonhershfield.com) as a mechanical design engineer (in training). I worked on a team with mechanical, evironmental, electrical, and control engineers on buildings, labratories, and condos. I then obtained my M.Sc at the [Ryerson Vision Lab](https://ryersonvisionlab.github.io/) in August 2020 under the co-supervision of [Dr. Neil Bruce](https://cs.ryerson.ca/~bruce/) and [Dr. Kosta Derpanis](https://cs.ryerson.ca/~kosta/). My M.Sc thesis focused on multi-modal action recognition. 

I am currently the Lead Scientist in Residence (SiR) at [NextAI](https://www.nextcanada.com/next-ai/), where I work as a technical consultant for multiple AI-based startups in Toronto. Some of the companies I have worked with are [Origami-XR](https://www.origami-xr.com/), [Future Fertility](https://futurefertility.com/), [VideoLogic](https://www.videologic.io/), [NoLeak Defence](https://www.noleak.io/), [Argentum](https://www.argentum.ai/).

My hobbies include health and fitness, competitive Super Smash Bros. Melee, birds, close up magic, and progressive house music.


## News

- I gave a talk at [Vector's Endless Summer School program](https://vectorinstitute.ai/programs-courses/endless-summer-school/) on Current Trends in Computer Vision and a CVPR 2022 Recap
- Paper accepted to the International Conference of Computer Vision (IJCV) - SegMix: Co-occurrence Driven Mixup for Semantic
Segmentation and Adversarial Robustness. [Paper](https://arxiv.org/abs/2108.09929). 
- New Preprint available on Arxiv - Quantifying and Learning Static vs. Dynamic Information in Deep Spatiotemporal Networks.
 [Paper](https://arxiv.org/abs/2211.01783)
- I presented a spolight presentation at the [Explainable AI for Computer Vision Workshop](https://xai4cv.github.io/workshop) at CVPR 2022. You can [watch the recorded talk here](https://www.youtube.com/watch?v=gpnmRG4aMHw&ab_channel=mkowal2).
- Paper Accpted to CVPR 2022 - A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information. [Paper](https://arxiv.org/abs/2206.02846) and [Project Page](https://yorkucvil.github.io/Static-Dynamic-Interpretability/).
- Paper Accepted to ICCV 2021 - Global Pooling, More than Meets the Eye: Position Information is Encoded Channel-Wise in CNNs. [Paper](https://arxiv.org/abs/2108.07884).
- Paper Accepted to BMVC 2021 - Simpler Does It: Generating Semantic Labels with Objectness Guidance. [Paper](https://arxiv.org/abs/2110.10335).
- Paper Accepted to ICLR 2021 - Shape or Texture: Understanding Discriminative Features in CNNs. [Paper](https://arxiv.org/abs/2101.11604).
- Paper Accepted as an Oral to BMVC 2020 - Feature Binding with Category-Dependant MixUp for Semantic Segmentation and Adversarial Robustness. [Paper](https://arxiv.org/abs/2008.05667).
